{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3 #input vector size for each time stamp\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_inputs = 3\n",
    "# n_neurons = 5\n",
    "# X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "# X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "# Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons],dtype=tf.float32))\n",
    "# Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons],dtype=tf.float32))\n",
    "# b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "# Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "# Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "# init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons],dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype = tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons]), dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanh funciton plotted\n",
    "# x = np.arange(-10, 10, 1)\n",
    "# y = np.tanh(x)\n",
    "# print(y)\n",
    "# plt.plot(x,y)\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx)+ b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) +  b)\n",
    "init = tf.initializers.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], \n",
    "                     [3, 4, 5], \n",
    "                     [6, 7, 8], \n",
    "                     [9, 0, 1]]) # at t=0\n",
    "X1_batch = np.array([[9, 8, 7], \n",
    "                     [0, 0, 0],\n",
    "                     [6, 5, 4],\n",
    "                     [3, 2, 1]]) #at t=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict = { X0: X0_batch, X1 : X1_batch}) #fetches can be list, ordered Data. here [Y0, Y1] as fetches \n",
    "#     print(Y0_val, Y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9779369   0.86674     0.4873942   0.90718687 -0.9229775 ]\n",
      " [ 1.          0.96986324  0.03596565  1.         -0.99999684]\n",
      " [ 1.          0.99346393 -0.43063378  1.         -1.        ]\n",
      " [ 0.99999964 -1.         -0.9988381   0.9994498  -0.99877286]]\n",
      "[[ 1.         -0.4508167  -0.8497606   1.         -1.        ]\n",
      " [ 0.9983719  -0.7717322   0.77549446  0.9670939  -0.70476377]\n",
      " [ 1.         -0.25396088 -0.31837085  1.         -0.9999998 ]\n",
      " [ 0.9999865  -0.95622706  0.13816315  0.9999336  -0.9974408 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)\n",
    "print(Y1_val)\n",
    "# print(X0_batch.shape, np.shape(X0), X1_batch.shape, np.shape(X1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USING TENSORFLOW FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_inputs = 3\n",
    "# n_neurons = 5\n",
    "# X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "# X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "# basicCell = tf.keras.layers.SimpleRNNCell(num_units = n_neurons, activation = tanh)\n",
    "# # staticCell = tf.contrib.rnn.static_rnn(num_uni)\n",
    "# states, outSeqs = tf.keras.layers.RNN(cell = basicCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "openFile = open(\"Alice.txt\", 'r')\n",
    "alice = openFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, WordPunctTokenizer\n",
    "# alice_sent = sent_tokenize(alice)\n",
    "# print(alice_sent[3:6])\n",
    "alice_word_tokens = WordPunctTokenizer().tokenize(alice)\n",
    "alice_stops = alice_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/bmrs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# stopwords.fileids()\n",
    "eng_stops = list(set(stopwords.words('english')))\n",
    "# print(eng_stops)\n",
    "alice_stops_free = [words for words in alice_stops if not words in eng_stops]\n",
    "# alice_stops_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_stops_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_stops_final = print([' '.join(alice_stops_free)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_alice = open(\"Alice.txt\", 'rb')\n",
    "words = []\n",
    "for word in file_alice:\n",
    "    word = word.strip().lower()\n",
    "    word = word.decode(\"ascii\", \"ignore\")\n",
    "    if len(word) == 0:\n",
    "        continue\n",
    "    words.append(word)\n",
    "file_alice.close()\n",
    "text = \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Indexes to characters.\n",
    "Make lookUp tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set([c for c in text])\n",
    "len_chars = len(chars)\n",
    "# list(enumerate(chars, start = 1))\n",
    "index2char = dict(enumerate(chars))\n",
    "char2index = dict((c,i) for i,c in enumerate(chars))\n",
    "# char2index[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158101"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"Alice_clean.txt\", \"w+\")\n",
    "f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = 10\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = [] #contains seqlen: 10 characters\n",
    "label_chars = []\n",
    "for i in range(0, len(text)- seqlen, step):\n",
    "    input_chars.append(text[i: i+seqlen])\n",
    "    label_chars.append(text[i + seqlen])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorize the input and label texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), seqlen, len_chars), dtype= np.bool)\n",
    "Y = np.zeros((len(input_chars), len_chars), dtype= np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    Y[i, char2index[label_chars[i]]] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUILDING OUR MODEL**\n",
    "- rnn OUTPUT DIMENSION SIZE = 128\n",
    "- WE WANT TO RETURN A SINGLE CHARACTER AS OUTPUT, not a sequence of characters,then return_sequences =Fasle\n",
    "- input to RNN i of shape: (seqlen, len_chars)\n",
    "- set unroll = True, improoves performance of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation = Softmax, gives character with the highest pobability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "num_iters = 35\n",
    "num_epochs_per_iter = 1\n",
    "num_preds_per_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units = 128, return_sequences = False, \n",
    "                    input_shape =(seqlen, len_chars), unroll = True))\n",
    "model.add(Dense(len_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "#specify loss funcion\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 14s 88us/step - loss: 2.3351\n",
      "generating from seed: of hjckrrh\n",
      "of hjckrrhe the said the guthe d at the gat she ghe she she she she she she she she she she she she she she sh==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 14s 88us/step - loss: 2.0475\n",
      "generating from seed: upon her: \n",
      "upon her: the was at in the was at in the was at in the was at in the was at in the was at in the was at in th==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 15s 94us/step - loss: 1.9442\n",
      "generating from seed: you mean, \n",
      "you mean, and the was suther alice and the was suther alice and the was suther alice and the was suther alice ==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 14s 91us/step - loss: 1.8637\n",
      "generating from seed:  were doin\n",
      " were doing and the project gutenberg-tm alice and the project gutenberg-tm alice and the project gutenberg-tm==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 15s 95us/step - loss: 1.7966\n",
      "generating from seed:  it usuall\n",
      " it usuall the master alice said the gat had the gat had the gat had the gat had the gat had the gat had the g==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 15s 94us/step - loss: 1.7404\n",
      "generating from seed: o speak, a\n",
      "o speak, and she had no she was she found the roon the lick as it was she had no she was she found the roon th==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 15s 96us/step - loss: 1.6942\n",
      "generating from seed: sed the wh\n",
      "sed the white the poos of the mock turtle the project gutenberg-tm alice the mouse for the dont of the project==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 16s 102us/step - loss: 1.6547\n",
      "generating from seed: appeared t\n",
      "appeared to a little sis soud alice said to a said to see she sears to the said to a said to see she sears to ==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 16s 99us/step - loss: 1.6207\n",
      "generating from seed: re were th\n",
      "re were the poor a work out to say to the porsont of the got and better the porse some of the poor a work out ==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 16s 100us/step - loss: 1.5920\n",
      "generating from seed: ey should \n",
      "ey should the white rabbit of the white rabbit of the white rabbit of the white rabbit of the white rabbit of ==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 17s 107us/step - loss: 1.5657\n",
      "generating from seed: long way. \n",
      "long way. the the took the the took the the took the the took the the took the the took the the took the the t==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 18s 112us/step - loss: 1.5449\n",
      "generating from seed: ort of way\n",
      "ort of way of the seally project gutenberg-tm little some of the seally project gutenberg-tm little some of th==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 18s 113us/step - loss: 1.5252\n",
      "generating from seed: g, display\n",
      "g, display dreat dreat dreat dreat dreat dreat dreat dreat dreat dreat dreat dreat dreat dreat dreat dreat dre==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 21s 134us/step - loss: 1.5076\n",
      "generating from seed: ple about \n",
      "ple about as the reading of the tried to herself and the poor a mear of the tried to herself and the poor a me==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 17s 111us/step - loss: 1.4929\n",
      "generating from seed:  sky. twin\n",
      " sky. twing a dine of the other she was a great down the other she was a great down the other she was a great ==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 17s 105us/step - loss: 1.4782\n",
      "generating from seed:  both bowe\n",
      " both bowed and the mock turtle said the mack the door the door the door the door the door the door the door t==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 16s 104us/step - loss: 1.4654\n",
      "generating from seed: he hatter,\n",
      "he hatter, and the mock turtle with the same to herself on the same to herself on the same to herself on the s==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 15s 95us/step - loss: 1.4544\n",
      "generating from seed:  certainly\n",
      " certainly got to the poor of course the work or great hare the work or great hare the work or great hare the ==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 15s 94us/step - loss: 1.4428\n",
      "generating from seed: charities \n",
      "charities to the trieled in a very done out of the trieled in a very done out of the trieled in a very done ou==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 16s 100us/step - loss: 1.4329\n",
      "generating from seed:  all that.\n",
      " all that. the for of the tried to herself, and the gryphon and the gryphon and the gryphon and the gryphon an==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 18s 112us/step - loss: 1.4247\n",
      "generating from seed: dable form\n",
      "dable formation of the room and she set the rook of the should got it as she said the dound go and she set the==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 19s 123us/step - loss: 1.4160\n",
      "generating from seed: t, you can\n",
      "t, you can least one of the work in the gryphon reperes the poor and she went on the hatter she was not a sear==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 18s 114us/step - loss: 1.4088\n",
      "generating from seed: table. hav\n",
      "table. have you was to the door all was a little began with a little began with a little began with a little b==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 20s 124us/step - loss: 1.4009\n",
      "generating from seed: ds! and th\n",
      "ds! and the mock turtle said to her ean she seent of the mock turtle said to her ean she seent of the mock tur==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 21s 134us/step - loss: 1.3938\n",
      "generating from seed:  such a hu\n",
      " such a hurried the mock turtle said to the poor little book and a some time and any and any and any and any a==================================================\n",
      "Iteration #: 25\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 23s 145us/step - loss: 1.3880\n",
      "generating from seed: i wonder h\n",
      "i wonder his short in the work and had been the work and had been the work and had been the work and had been ==================================================\n",
      "Iteration #: 26\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 20s 124us/step - loss: 1.3821\n",
      "generating from seed: rch.  they\n",
      "rch.  they would be no any roon the mock turtle of the work in a to do a round alice again, and she went on a ==================================================\n",
      "Iteration #: 27\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 23s 145us/step - loss: 1.3766\n",
      "generating from seed: s:-- beaut\n",
      "s:-- beauting to say the queen the gryphon in the work in a some to see the put or his sleep of the shall be a==================================================\n",
      "Iteration #: 28\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 26s 162us/step - loss: 1.3702\n",
      "generating from seed:  be kind t\n",
      " be kind the thing as it was a little thing as it was a little thing as it was a little thing as it was a litt==================================================\n",
      "Iteration #: 29\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 19s 123us/step - loss: 1.3666\n",
      "generating from seed:  all you k\n",
      " all you know in a mouse of the door of the thous or once a grow where what i had or come on the read remery o==================================================\n",
      "Iteration #: 30\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 21s 131us/step - loss: 1.3609\n",
      "generating from seed: nd? she sa\n",
      "nd? she said to herself an replied to she had the king said to the know what the know. the king said to the kn==================================================\n",
      "Iteration #: 31\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 20s 126us/step - loss: 1.3567\n",
      "generating from seed: iven by th\n",
      "iven by the way to get to the king said to the project gutenberg-tm electronic works in the work thing mary se==================================================\n",
      "Iteration #: 32\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 22s 140us/step - loss: 1.3523\n",
      "generating from seed: they wont \n",
      "they wont to the words the words the words the words the words the words the words the words the words the wor==================================================\n",
      "Iteration #: 33\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 18s 111us/step - loss: 1.3491\n",
      "generating from seed: was, no do\n",
      "was, no down a little begin to the such a little begin to the such a little begin to the such a little begin t==================================================\n",
      "Iteration #: 34\n",
      "Epoch 1/1\n",
      "158091/158091 [==============================] - 21s 136us/step - loss: 1.3442\n",
      "generating from seed: ength, whi\n",
      "ength, while she had not any of the white rabbit so she said to herself the white rabbit so she said to hersel\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iters):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" %(i))\n",
    "    model.fit(X, Y, batch_size = batch_size, epochs = num_epochs_per_iter)\n",
    "    \n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"generating from seed: %s\" %(test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(num_preds_per_epoch):\n",
    "        Xtest = np.zeros((1, seqlen, len_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        #move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
